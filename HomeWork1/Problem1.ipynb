{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrutask/Machine_Learning/blob/master/HomeWork1/Problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CqiUNMXz19-p",
        "colab_type": "code",
        "outputId": "fc230468-0d0a-419f-badd-3a2fc8541c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KfbP1x7t2SG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class logistic_regression():\n",
        "  \n",
        "  def __init__(self, size):\n",
        "    \n",
        "    self.weights = np.zeros((size,1))\n",
        "    self.bias = 0.0\n",
        "    self.accuracy=0.0\n",
        "      \n",
        "  \n",
        "  def train_and_optimize(self, train_x, train_y, learning_rate=0.01, num_iters=50, mini_batch_size=200):\n",
        "    \n",
        "    w = np.zeros((train_x.shape[0],1))\n",
        "    b=0.0\n",
        "    m = train_x.shape[1]   #no of training smaples\n",
        "    print(\"No of training examples:\", m)\n",
        "    num_batches=int(m/mini_batch_size)\n",
        "    costs=[] \n",
        "    \n",
        "    #mini batch gradient descent\n",
        "    for i in range(num_iters):\n",
        "      \n",
        "      batch_cost=[]\n",
        "      shuffled_indices = np.random.permutation(m)       \n",
        "      train_x = train_x[:,shuffled_indices]\n",
        "      train_y = train_y[shuffled_indices]\n",
        "      start=0\n",
        "      end=mini_batch_size-1\n",
        "      \n",
        "      for j in range(num_batches):\n",
        "        X=train_x[:, start:end]\n",
        "        Y=train_y[start:end]\n",
        "        \n",
        "        A = 1/(1 + np.exp(-((np.dot(w.transpose(),X))+ b)))  # compute activation\n",
        "        #Mean Squared Error\n",
        "        cost = (-1/mini_batch_size) *  np.sum(np.dot((A-Y).transpose(),(A-Y)))\n",
        "        \n",
        "        dz=np.dot(A.transpose(),(1-A))\n",
        "        temp=np.dot(X, dz)\n",
        "        dw = (1/mini_batch_size) * np.dot(temp,(A-Y).transpose())\n",
        "        db = (1/mini_batch_size) * np.sum(np.dot(dz,(A-Y).transpose()))\n",
        "        cost = np.squeeze(cost)\n",
        "  \n",
        "        w = w - learning_rate * dw\n",
        "        b = b - learning_rate * db\n",
        "        \n",
        "        batch_cost.append(cost)\n",
        "        start=start+mini_batch_size\n",
        "        end=end+mini_batch_size\n",
        "        \n",
        "      costs.append(sum(batch_cost) / len(batch_cost))\n",
        "    \n",
        "      if i%25==0 or i==num_iters-1:\n",
        "        print(\"Cost after {} iterations: {}\".format(i, sum(costs)/len(costs)))\n",
        "    \n",
        "    self.weights=w\n",
        "    self.bias=b\n",
        "    \n",
        " \n",
        "  def predict(self, test_x, Label):\n",
        "  \n",
        "    A = 1/(1 + np.exp(-((np.dot(self.weights.transpose(),test_x))+ self.bias)))\n",
        "    m = A.shape[1]\n",
        "    Y_pred = np.zeros((1, m))\n",
        "  \n",
        "    for i in range(A.shape[1]):\n",
        "      # Convert probabilities A to actual predictions\n",
        "        \n",
        "      if A[0,i]<= 0.5 :\n",
        "        Y_pred[0, i] = 0\n",
        "      else :\n",
        "        Y_pred[0, i] = 1\n",
        "  \n",
        "    self.accuracy=((np.sum(Y_pred==Label))/m) * 100\n",
        "    \n",
        "    return(self.accuracy)\n",
        "  \n",
        "  \n",
        "  def calc_probability(self, image_features):\n",
        "    \n",
        "    prob=1/(1 + np.exp(-((np.dot(self.weights.transpose(),image_features))+ self.bias)))\n",
        "    \n",
        "    return(prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHRGOBVr2oEX",
        "colab_type": "code",
        "outputId": "9c0f6d30-9348-48a3-99dc-10db2a4a14d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1495
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "train_x_flat = x_train.reshape(x_train.shape[0],-1).T\n",
        "test_x_flat = x_test.reshape(x_test.shape[0],-1).T\n",
        "\n",
        "train_x, test_x = train_x_flat / 255.0, test_x_flat / 255.0\n",
        "print(\"Size of training data:\",train_x.shape)\n",
        "print(\"Size of test data:\",test_x.shape)\n",
        "\n",
        "#one hot encoding of the labels\n",
        "train_y= np.eye(10)[y_train]\n",
        "test_y = np.eye(10)[y_test]\n",
        "print(\"Size of training labels:\", train_y.shape)\n",
        "print(\"Size of test labels:\", test_y.shape)\n",
        "\n",
        "no_classes=10  #0 to 9 digits\n",
        "\n",
        "#one vs all approach\n",
        "digits=[]\n",
        "for i in range(no_classes):\n",
        "  lgr=logistic_regression(train_x.shape[0])\n",
        "  print(\"\\nTraining class {} vs others.....\".format(i))\n",
        "  lgr.train_and_optimize(train_x, train_y[:,i])\n",
        "  acc=lgr.predict(test_x, test_y[:,i])\n",
        "  print(\"\\nAccuracy of predicting {} is: {}\".format(i, acc))\n",
        "  digits.append(lgr)\n",
        "  "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training data: (784, 60000)\n",
            "Size of test data: (784, 10000)\n",
            "Size of training labels: (60000, 10)\n",
            "Size of test labels: (10000, 10)\n",
            "\n",
            "Training class 0 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.8040365634559914\n",
            "Cost after 25 iterations: -0.12094322440298591\n",
            "Cost after 49 iterations: -0.09523022735422466\n",
            "\n",
            "Accuracy of predicting 0 is: 97.6\n",
            "\n",
            "Training class 1 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.6551285109744046\n",
            "Cost after 25 iterations: -0.13103212441687703\n",
            "Cost after 49 iterations: -0.10993455330186588\n",
            "\n",
            "Accuracy of predicting 1 is: 98.6\n",
            "\n",
            "Training class 2 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.5193783089415596\n",
            "Cost after 25 iterations: -0.10651380699903444\n",
            "Cost after 49 iterations: -0.08732881460653807\n",
            "\n",
            "Accuracy of predicting 2 is: 95.43\n",
            "\n",
            "Training class 3 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.5446238286455929\n",
            "Cost after 25 iterations: -0.10688344832166988\n",
            "Cost after 49 iterations: -0.08932639584141794\n",
            "\n",
            "Accuracy of predicting 3 is: 96.11\n",
            "\n",
            "Training class 4 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.5217870905233298\n",
            "Cost after 25 iterations: -0.10370705389365563\n",
            "Cost after 49 iterations: -0.08904822839507982\n",
            "\n",
            "Accuracy of predicting 4 is: 96.16\n",
            "\n",
            "Training class 5 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.4833683511258393\n",
            "Cost after 25 iterations: -0.10161470843790148\n",
            "Cost after 49 iterations: -0.08740879966944964\n",
            "\n",
            "Accuracy of predicting 5 is: 95.19\n",
            "\n",
            "Training class 6 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.8029193593872433\n",
            "Cost after 25 iterations: -0.1182290981081189\n",
            "Cost after 49 iterations: -0.09510132997396874\n",
            "\n",
            "Accuracy of predicting 6 is: 97.05\n",
            "\n",
            "Training class 7 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.574936236855501\n",
            "Cost after 25 iterations: -0.11294825793168119\n",
            "Cost after 49 iterations: -0.09297484382633987\n",
            "\n",
            "Accuracy of predicting 7 is: 96.85000000000001\n",
            "\n",
            "Training class 8 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.6537643597232243\n",
            "Cost after 25 iterations: -0.1292764151141992\n",
            "Cost after 49 iterations: -0.1050955728380329\n",
            "\n",
            "Accuracy of predicting 8 is: 92.60000000000001\n",
            "\n",
            "Training class 9 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: -0.4033829959078806\n",
            "Cost after 25 iterations: -0.10215513950962846\n",
            "Cost after 49 iterations: -0.08849181898488218\n",
            "\n",
            "Accuracy of predicting 9 is: 94.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_anf00_2wcA",
        "colab_type": "code",
        "outputId": "ac432e20-744b-41b8-c9a1-4464f4c02676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        }
      },
      "cell_type": "code",
      "source": [
        "No_to_predict = input(\"Enter any image from 0 to 60000 for prediction: \")\n",
        "\n",
        "plt.imshow(train_x[:,int(No_to_predict)].reshape((28,28)))\n",
        "predictions=[]\n",
        "\n",
        "for i in range(no_classes):\n",
        "  lgr=digits[i]\n",
        "  prob=lgr.calc_probability(train_x[:,int(No_to_predict)])\n",
        "  print(\"\\nProbability of the number being {} is: {}\".format(i, prob))\n",
        "  predictions.append(prob)\n",
        "  \n",
        "preds=np.asarray(predictions)\n",
        "print(\"\\nPredicted number is:\",np.argmax(preds))\n",
        "  "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter any image from 0 to 60000 for prediction: 8976\n",
            "\n",
            "Probability of the number being 0 is: [0.00881326]\n",
            "\n",
            "Probability of the number being 1 is: [0.01853183]\n",
            "\n",
            "Probability of the number being 2 is: [0.02102553]\n",
            "\n",
            "Probability of the number being 3 is: [0.94637725]\n",
            "\n",
            "Probability of the number being 4 is: [0.0029639]\n",
            "\n",
            "Probability of the number being 5 is: [0.13360925]\n",
            "\n",
            "Probability of the number being 6 is: [0.00026997]\n",
            "\n",
            "Probability of the number being 7 is: [0.0027561]\n",
            "\n",
            "Probability of the number being 8 is: [0.04089285]\n",
            "\n",
            "Probability of the number being 9 is: [0.00073346]\n",
            "\n",
            "Predicted number is: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwP8Djm/5BhQ2x9wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}