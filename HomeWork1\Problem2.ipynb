{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrutask/Machine_Learning/blob/master/HomeWork1%5CProblem2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cy7NV3JVc3u6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "068b23d3-cbbf-464c-bb65-ad4d182ecb9e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdNrXFElKHdo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class logistic_regression():\n",
        "  \n",
        "  def __init__(self, size):\n",
        "    \n",
        "    self.weights = np.zeros((size,1))\n",
        "    self.bias = 0.0\n",
        "    self.accuracy=0.0\n",
        "      \n",
        "  \n",
        "  def train_and_optimize(self, train_x, train_y, learning_rate=0.05, num_iters=50, mini_batch_size=200):\n",
        "    \n",
        "    w = np.zeros((train_x.shape[0],1))\n",
        "    b=0.0\n",
        "    m = train_x.shape[1]   #no of training smaples\n",
        "    print(\"No of training examples:\", m)\n",
        "    num_batches=int(m/mini_batch_size)\n",
        "    costs=[] \n",
        "    \n",
        "    #mini batch gradient descent\n",
        "    for i in range(num_iters):\n",
        "      \n",
        "      batch_cost=[]\n",
        "      shuffled_indices = np.random.permutation(m)       \n",
        "      train_x = train_x[:,shuffled_indices]\n",
        "      train_y = train_y[shuffled_indices]\n",
        "      start=0\n",
        "      end=mini_batch_size-1\n",
        "      \n",
        "      for j in range(num_batches):\n",
        "        X=train_x[:, start:end]\n",
        "        Y=train_y[start:end]\n",
        "        \n",
        "        A = 1/(1 + np.exp(-((np.dot(w.transpose(),X))+ b)))  # compute activation\n",
        "        cost = (-1/mini_batch_size) *  np.sum(np.multiply(Y, np.log(A)) + np.multiply((1-Y), np.log(1-A)))\n",
        "        dw = (1/mini_batch_size) * X.dot((A-Y).transpose())\n",
        "        db = (1/mini_batch_size) * np.sum((A-Y))\n",
        "        cost = np.squeeze(cost)\n",
        "  \n",
        "        w = w - learning_rate * dw\n",
        "        b = b - learning_rate * db\n",
        "        \n",
        "        batch_cost.append(cost)\n",
        "        start=start+mini_batch_size\n",
        "        end=end+mini_batch_size\n",
        "        \n",
        "      costs.append(sum(batch_cost) / len(batch_cost))\n",
        "    \n",
        "      if i%25==0 or i==num_iters-1:\n",
        "        print(\"Cost after {} iterations: {}\".format(i, sum(costs)/len(costs)))\n",
        "    \n",
        "    self.weights=w\n",
        "    self.bias=b\n",
        "    \n",
        " \n",
        "  def predict(self, test_x, Label):\n",
        "  \n",
        "    A = 1/(1 + np.exp(-((np.dot(self.weights.transpose(),test_x))+ self.bias)))\n",
        "    m = A.shape[1]\n",
        "    Y_pred = np.zeros((1, m))\n",
        "  \n",
        "    for i in range(A.shape[1]):\n",
        "      # Convert probabilities A to actual predictions\n",
        "        \n",
        "      if A[0,i]<= 0.5 :\n",
        "        Y_pred[0, i] = 0\n",
        "      else :\n",
        "        Y_pred[0, i] = 1\n",
        "  \n",
        "    self.accuracy=((np.sum(Y_pred==Label))/m) * 100\n",
        "    \n",
        "    return(self.accuracy)\n",
        "  \n",
        "  \n",
        "  def calc_probability(self, image_features):\n",
        "    \n",
        "    prob=1/(1 + np.exp(-((np.dot(self.weights.transpose(),image_features))+ self.bias)))\n",
        "    \n",
        "    return(prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNIX_-BH16xb",
        "colab_type": "code",
        "outputId": "68065eac-ad42-4c9e-97a1-19834f8f5a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1530
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "train_x_flat = x_train.reshape(x_train.shape[0],-1).T\n",
        "test_x_flat = x_test.reshape(x_test.shape[0],-1).T\n",
        "\n",
        "train_x, test_x = train_x_flat / 255.0, test_x_flat / 255.0\n",
        "print(\"Size of training data:\",train_x.shape)\n",
        "print(\"Size of test data:\",test_x.shape)\n",
        "\n",
        "#one hot encoding of the labels\n",
        "train_y= np.eye(10)[y_train]\n",
        "test_y = np.eye(10)[y_test]\n",
        "print(\"Size of training labels:\", train_y.shape)\n",
        "print(\"Size of test labels:\", test_y.shape)\n",
        "\n",
        "no_classes=10  #0 to 9 digits\n",
        "\n",
        "#one vs all approach\n",
        "digits=[]\n",
        "for i in range(no_classes):\n",
        "  lgr=logistic_regression(train_x.shape[0])\n",
        "  print(\"\\nTraining class {} vs others.....\".format(i))\n",
        "  lgr.train_and_optimize(train_x, train_y[:,i])\n",
        "  acc=lgr.predict(test_x, test_y[:,i])\n",
        "  print(\"\\nAccuracy of predicting {} is: {}\".format(i, acc))\n",
        "  digits.append(lgr)\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "Size of training data: (784, 60000)\n",
            "Size of test data: (784, 10000)\n",
            "Size of training labels: (60000, 10)\n",
            "Size of test labels: (10000, 10)\n",
            "\n",
            "Training class 0 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.1150774877059402\n",
            "Cost after 25 iterations: 0.04120530401752427\n",
            "Cost after 49 iterations: 0.0357538931576745\n",
            "\n",
            "Accuracy of predicting 0 is: 99.22\n",
            "\n",
            "Training class 1 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.10395679694410086\n",
            "Cost after 25 iterations: 0.04012029430385119\n",
            "Cost after 49 iterations: 0.03591194481807448\n",
            "\n",
            "Accuracy of predicting 1 is: 99.33999999999999\n",
            "\n",
            "Training class 2 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.17382539285821128\n",
            "Cost after 25 iterations: 0.08560554656768907\n",
            "Cost after 49 iterations: 0.07921438408785166\n",
            "\n",
            "Accuracy of predicting 2 is: 98.08\n",
            "\n",
            "Training class 3 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.18158528734152948\n",
            "Cost after 25 iterations: 0.09875492466908839\n",
            "Cost after 49 iterations: 0.09191463801704249\n",
            "\n",
            "Accuracy of predicting 3 is: 97.81\n",
            "\n",
            "Training class 4 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.15995435187606008\n",
            "Cost after 25 iterations: 0.07022835239833214\n",
            "Cost after 49 iterations: 0.06360963148479022\n",
            "\n",
            "Accuracy of predicting 4 is: 98.14\n",
            "\n",
            "Training class 5 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.20162443805224511\n",
            "Cost after 25 iterations: 0.11089833144544371\n",
            "Cost after 49 iterations: 0.10298325535252373\n",
            "\n",
            "Accuracy of predicting 5 is: 97.43\n",
            "\n",
            "Training class 6 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.13703031440873792\n",
            "Cost after 25 iterations: 0.053713764948193736\n",
            "Cost after 49 iterations: 0.04829431002641932\n",
            "\n",
            "Accuracy of predicting 6 is: 98.69\n",
            "\n",
            "Training class 7 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.135850773785163\n",
            "Cost after 25 iterations: 0.061190744685059556\n",
            "Cost after 49 iterations: 0.056405377183049527\n",
            "\n",
            "Accuracy of predicting 7 is: 98.5\n",
            "\n",
            "Training class 8 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.25014112271723393\n",
            "Cost after 25 iterations: 0.14469233144954827\n",
            "Cost after 49 iterations: 0.13281482150960897\n",
            "\n",
            "Accuracy of predicting 8 is: 96.06\n",
            "\n",
            "Training class 9 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.2125680850259475\n",
            "Cost after 25 iterations: 0.12102611370902472\n",
            "Cost after 49 iterations: 0.11301473281155705\n",
            "\n",
            "Accuracy of predicting 9 is: 96.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZDuLaQ2m0-X8",
        "colab_type": "code",
        "outputId": "77d74e20-b2ac-45c0-bccf-a313fd29a8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        }
      },
      "cell_type": "code",
      "source": [
        "No_to_predict = input(\"Enter any image from 0 to 60000 for prediction: \")\n",
        "\n",
        "plt.imshow(train_x[:,int(No_to_predict)].reshape((28,28)))\n",
        "predictions=[]\n",
        "\n",
        "for i in range(no_classes):\n",
        "  lgr=digits[i]\n",
        "  prob=lgr.calc_probability(train_x[:,int(No_to_predict)])\n",
        "  print(\"\\nProbability of the number being {} is: {}\".format(i, prob))\n",
        "  predictions.append(prob)\n",
        "  \n",
        "preds=np.asarray(predictions)\n",
        "print(\"\\nPredicted number is:\",np.argmax(preds))\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter any image from 0 to 60000 for prediction: 65\n",
            "\n",
            "Probability of the number being 0 is: [0.00032935]\n",
            "\n",
            "Probability of the number being 1 is: [0.03263727]\n",
            "\n",
            "Probability of the number being 2 is: [0.00295756]\n",
            "\n",
            "Probability of the number being 3 is: [0.01795521]\n",
            "\n",
            "Probability of the number being 4 is: [0.01808715]\n",
            "\n",
            "Probability of the number being 5 is: [0.99530527]\n",
            "\n",
            "Probability of the number being 6 is: [0.00111035]\n",
            "\n",
            "Probability of the number being 7 is: [0.0002998]\n",
            "\n",
            "Probability of the number being 8 is: [0.16955276]\n",
            "\n",
            "Probability of the number being 9 is: [1.52865174e-05]\n",
            "\n",
            "Predicted number is: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}