{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrutask/Machine_Learning/blob/master/HomeWork1/Problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CqiUNMXz19-p",
        "colab_type": "code",
        "outputId": "fc230468-0d0a-419f-badd-3a2fc8541c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KfbP1x7t2SG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class logistic_regression():\n",
        "  \n",
        "  def __init__(self, size):\n",
        "    \n",
        "    self.weights = np.zeros((size,1))\n",
        "    self.bias = 0.0\n",
        "    self.accuracy=0.0\n",
        "      \n",
        "  \n",
        "  def train_and_optimize(self, train_x, train_y, learning_rate=0.01, num_iters=50, mini_batch_size=200):\n",
        "    \n",
        "    w = np.zeros((train_x.shape[0],1))\n",
        "    b=0.0\n",
        "    m = train_x.shape[1]   #no of training smaples\n",
        "    print(\"No of training examples:\", m)\n",
        "    num_batches=int(m/mini_batch_size)\n",
        "    costs=[] \n",
        "    \n",
        "    #mini batch gradient descent\n",
        "    for i in range(num_iters):\n",
        "      \n",
        "      batch_cost=[]\n",
        "      shuffled_indices = np.random.permutation(m)       \n",
        "      train_x = train_x[:,shuffled_indices]\n",
        "      train_y = train_y[shuffled_indices]\n",
        "      start=0\n",
        "      end=mini_batch_size-1\n",
        "      \n",
        "      for j in range(num_batches):\n",
        "        X=train_x[:, start:end]\n",
        "        Y=train_y[start:end]\n",
        "        \n",
        "        A = 1/(1 + np.exp(-((np.dot(w.transpose(),X))+ b)))  # compute activation\n",
        "        \n",
        "        cost = (1/mini_batch_size) *  np.sum(np.dot((A-Y).transpose(),(A-Y)))\n",
        "        \n",
        "        dz=np.dot(A.transpose(),(1-A))\n",
        "        temp=np.dot(X, dz)\n",
        "        dw = (1/mini_batch_size) * np.dot(temp,(A-Y).transpose())\n",
        "        db = (1/mini_batch_size) * np.sum(np.dot(dz,(A-Y).transpose()))\n",
        "        cost = np.squeeze(cost)\n",
        "  \n",
        "        w = w - learning_rate * dw\n",
        "        b = b - learning_rate * db\n",
        "        \n",
        "        batch_cost.append(cost)\n",
        "        start=start+mini_batch_size\n",
        "        end=end+mini_batch_size\n",
        "        \n",
        "      costs.append(sum(batch_cost) / len(batch_cost))\n",
        "    \n",
        "      if i%25==0 or i==num_iters-1:\n",
        "        print(\"Cost after {} iterations: {}\".format(i, sum(costs)/len(costs)))\n",
        "    \n",
        "    self.weights=w\n",
        "    self.bias=b\n",
        "    \n",
        " \n",
        "  def predict(self, test_x, Label):\n",
        "  \n",
        "    A = 1/(1 + np.exp(-((np.dot(self.weights.transpose(),test_x))+ self.bias)))\n",
        "    m = A.shape[1]\n",
        "    Y_pred = np.zeros((1, m))\n",
        "  \n",
        "    for i in range(A.shape[1]):\n",
        "      # Convert probabilities A to actual predictions\n",
        "        \n",
        "      if A[0,i]<= 0.5 :\n",
        "        Y_pred[0, i] = 0\n",
        "      else :\n",
        "        Y_pred[0, i] = 1\n",
        "  \n",
        "    self.accuracy=((np.sum(Y_pred==Label))/m) * 100\n",
        "    \n",
        "    return(self.accuracy)\n",
        "  \n",
        "  \n",
        "  def calc_probability(self, image_features):\n",
        "    \n",
        "    prob=1/(1 + np.exp(-((np.dot(self.weights.transpose(),image_features))+ self.bias)))\n",
        "    \n",
        "    return(prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHRGOBVr2oEX",
        "colab_type": "code",
        "outputId": "24b7afb3-6f3a-4cad-e2c1-149056a2aadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1495
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "train_x_flat = x_train.reshape(x_train.shape[0],-1).T\n",
        "test_x_flat = x_test.reshape(x_test.shape[0],-1).T\n",
        "\n",
        "train_x, test_x = train_x_flat / 255.0, test_x_flat / 255.0\n",
        "print(\"Size of training data:\",train_x.shape)\n",
        "print(\"Size of test data:\",test_x.shape)\n",
        "\n",
        "#one hot encoding of the labels\n",
        "train_y= np.eye(10)[y_train]\n",
        "test_y = np.eye(10)[y_test]\n",
        "print(\"Size of training labels:\", train_y.shape)\n",
        "print(\"Size of test labels:\", test_y.shape)\n",
        "\n",
        "no_classes=10  #0 to 9 digits\n",
        "\n",
        "\"\"\"digit0=logistic_regression(train_x.shape[0])\n",
        "digit0.train_and_optimize(train_x, train_y[:,0])\n",
        "acc=digit0.predict(test_x, test_y[:,0])\n",
        "print(\"\\nAccuracy of predicting 0 is: {}\".format(acc))\"\"\"\n",
        "\n",
        "#one vs all approach\n",
        "digits=[]\n",
        "for i in range(no_classes):\n",
        "  lgr=logistic_regression(train_x.shape[0])\n",
        "  print(\"\\nTraining class {} vs others.....\".format(i))\n",
        "  lgr.train_and_optimize(train_x, train_y[:,i])\n",
        "  acc=lgr.predict(test_x, test_y[:,i])\n",
        "  print(\"\\nAccuracy of predicting {} is: {}\".format(i, acc))\n",
        "  digits.append(lgr)\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training data: (784, 60000)\n",
            "Size of test data: (784, 10000)\n",
            "Size of training labels: (60000, 10)\n",
            "Size of test labels: (10000, 10)\n",
            "\n",
            "Training class 0 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.6798097245453089\n",
            "Cost after 25 iterations: 0.114294699598188\n",
            "Cost after 49 iterations: 0.09179983502944764\n",
            "\n",
            "Accuracy of predicting 0 is: 97.6\n",
            "\n",
            "Training class 1 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.7374997307436462\n",
            "Cost after 25 iterations: 0.13341583483589584\n",
            "Cost after 49 iterations: 0.11162209145175868\n",
            "\n",
            "Accuracy of predicting 1 is: 98.61\n",
            "\n",
            "Training class 2 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.6278296457883797\n",
            "Cost after 25 iterations: 0.10765162389033403\n",
            "Cost after 49 iterations: 0.08653324176668611\n",
            "\n",
            "Accuracy of predicting 2 is: 96.28\n",
            "\n",
            "Training class 3 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.7741059081261095\n",
            "Cost after 25 iterations: 0.11706035786665092\n",
            "Cost after 49 iterations: 0.0911525527180517\n",
            "\n",
            "Accuracy of predicting 3 is: 96.16\n",
            "\n",
            "Training class 4 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.6740673401857101\n",
            "Cost after 25 iterations: 0.10966833740333638\n",
            "Cost after 49 iterations: 0.09164290593035233\n",
            "\n",
            "Accuracy of predicting 4 is: 96.41\n",
            "\n",
            "Training class 5 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.5124085794065262\n",
            "Cost after 25 iterations: 0.10117928506641158\n",
            "Cost after 49 iterations: 0.08677395993157394\n",
            "\n",
            "Accuracy of predicting 5 is: 95.12\n",
            "\n",
            "Training class 6 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.8263290250134386\n",
            "Cost after 25 iterations: 0.11802899042119414\n",
            "Cost after 49 iterations: 0.09540064138068334\n",
            "\n",
            "Accuracy of predicting 6 is: 97.23\n",
            "\n",
            "Training class 7 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.6236232450637311\n",
            "Cost after 25 iterations: 0.11265439857890858\n",
            "Cost after 49 iterations: 0.09042793506856428\n",
            "\n",
            "Accuracy of predicting 7 is: 97.28999999999999\n",
            "\n",
            "Training class 8 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.8123046697830117\n",
            "Cost after 25 iterations: 0.13581743165297624\n",
            "Cost after 49 iterations: 0.10634515673478286\n",
            "\n",
            "Accuracy of predicting 8 is: 93.11\n",
            "\n",
            "Training class 9 vs others.....\n",
            "No of training examples: 60000\n",
            "Cost after 0 iterations: 0.6164937160188926\n",
            "Cost after 25 iterations: 0.11181632838590926\n",
            "Cost after 49 iterations: 0.09409409358986551\n",
            "\n",
            "Accuracy of predicting 9 is: 94.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_anf00_2wcA",
        "colab_type": "code",
        "outputId": "add8e44b-e4be-49ca-c09a-6ebea0366a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        }
      },
      "cell_type": "code",
      "source": [
        "No_to_predict = input(\"Enter any image from 0 to 60000 for prediction: \")\n",
        "\n",
        "plt.imshow(train_x[:,int(No_to_predict)].reshape((28,28)))\n",
        "predictions=[]\n",
        "\n",
        "for i in range(no_classes):\n",
        "  lgr=digits[i]\n",
        "  prob=lgr.calc_probability(train_x[:,int(No_to_predict)])\n",
        "  print(\"\\nProbability of the number being {} is: {}\".format(i, prob))\n",
        "  predictions.append(prob)\n",
        "  \n",
        "preds=np.asarray(predictions)\n",
        "print(\"\\nPredicted number is:\",np.argmax(preds))\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter any image from 0 to 60000 for prediction: 45\n",
            "\n",
            "Probability of the number being 0 is: [0.00354768]\n",
            "\n",
            "Probability of the number being 1 is: [0.00183289]\n",
            "\n",
            "Probability of the number being 2 is: [0.00151818]\n",
            "\n",
            "Probability of the number being 3 is: [0.00560086]\n",
            "\n",
            "Probability of the number being 4 is: [0.10520628]\n",
            "\n",
            "Probability of the number being 5 is: [0.01929952]\n",
            "\n",
            "Probability of the number being 6 is: [0.00263013]\n",
            "\n",
            "Probability of the number being 7 is: [0.07403923]\n",
            "\n",
            "Probability of the number being 8 is: [0.02433697]\n",
            "\n",
            "Probability of the number being 9 is: [0.82823841]\n",
            "\n",
            "Predicted number is: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}