{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_FinalArc.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrutask/Machine_Learning/blob/master/HomeWork2/CNN_FinalArc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QKJOa5A3fiuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f73ba77e-5ffb-46b6-8144-859b7d0e2295"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aNAo2foafnKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "46d56cb3-0cf3-4a0c-93de-64d13ef172d7"
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(\"X_train Size :\",X_train.shape)\n",
        "print(\"X_test Size : \",X_test.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 22s 0us/step\n",
            "X_train Size : (50000, 32, 32, 3)\n",
            "X_test Size :  (10000, 32, 32, 3)\n",
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wszVzhBvftFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7ce2680-9ed0-4923-d27f-eef734ca8dbb"
      },
      "cell_type": "code",
      "source": [
        "num_classes=10\n",
        "epoch=100\n",
        "\n",
        "print(\"Size of train, validation and test labels: \", y_train.shape, y_test.shape) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train, validation and test labels:  (50000, 1) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wDm__SgKftSZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "po0RdbA5f-TC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5898
        },
        "outputId": "c81b3e4f-195a-4148-c62e-43f883d29f4c"
      },
      "cell_type": "code",
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "scores = []\n",
        "input_dim=X_train.shape[1:]\n",
        "for train_index, val_index in kfold.split(X_train, y_train):\n",
        "  print(\"___________________________________________________________________________________________________________________\")\n",
        "  trainx=X_train[train_index]\n",
        "  trainy=y_train[train_index]\n",
        "  valx=X_train[val_index]\n",
        "  valy=y_train[val_index]\n",
        "  trainy = keras.utils.to_categorical(trainy, num_classes)\n",
        "  valy= keras.utils.to_categorical(valy, num_classes)\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_dim, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "  model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(800, activation='relu'))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  opt = optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  datagen = ImageDataGenerator(featurewise_center=False,samplewise_center=False,featurewise_std_normalization=False,samplewise_std_normalization=False, zca_whitening=False,\n",
        "        zca_epsilon=1e-06, rotation_range=10,width_shift_range=0.1, height_shift_range=0.2, shear_range=0., zoom_range=0.,channel_shift_range=0., fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0)\n",
        "\n",
        "  datagen.fit(trainx)\n",
        "  \n",
        "  model.fit_generator(datagen.flow(trainx, trainy), steps_per_epoch=1000, epochs=100, validation_data=(valx, valy))\n",
        "  score = model.evaluate(valx, valy, verbose=0) \n",
        "  scores.append(score[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "___________________________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 1.9005 - acc: 0.3009 - val_loss: 1.6189 - val_acc: 0.4201\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.6507 - acc: 0.4001 - val_loss: 1.4592 - val_acc: 0.4686\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.5280 - acc: 0.4447 - val_loss: 1.5930 - val_acc: 0.4486\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 1.4388 - acc: 0.4803 - val_loss: 1.2840 - val_acc: 0.5383\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 1.3783 - acc: 0.5022 - val_loss: 1.2676 - val_acc: 0.5514\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.3070 - acc: 0.5317 - val_loss: 1.1701 - val_acc: 0.5852\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.2426 - acc: 0.5580 - val_loss: 1.1495 - val_acc: 0.5934\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.2063 - acc: 0.5690 - val_loss: 1.1233 - val_acc: 0.6055\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1633 - acc: 0.5869 - val_loss: 1.1679 - val_acc: 0.5856\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1274 - acc: 0.5993 - val_loss: 1.0814 - val_acc: 0.6136\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0834 - acc: 0.6168 - val_loss: 1.0868 - val_acc: 0.6153\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0719 - acc: 0.6179 - val_loss: 0.9620 - val_acc: 0.6568\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0366 - acc: 0.6354 - val_loss: 0.9914 - val_acc: 0.6483\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0059 - acc: 0.6398 - val_loss: 0.9145 - val_acc: 0.6793\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9837 - acc: 0.6507 - val_loss: 0.8976 - val_acc: 0.6848\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9634 - acc: 0.6602 - val_loss: 0.9324 - val_acc: 0.6759\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9533 - acc: 0.6631 - val_loss: 1.0004 - val_acc: 0.6554\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9219 - acc: 0.6740 - val_loss: 0.8676 - val_acc: 0.6895\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9134 - acc: 0.6772 - val_loss: 0.9434 - val_acc: 0.6695\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8989 - acc: 0.6828 - val_loss: 0.8789 - val_acc: 0.6950\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8838 - acc: 0.6907 - val_loss: 0.8048 - val_acc: 0.7166\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8628 - acc: 0.6983 - val_loss: 0.7867 - val_acc: 0.7272\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8578 - acc: 0.6966 - val_loss: 0.8835 - val_acc: 0.6971\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8465 - acc: 0.7015 - val_loss: 0.7683 - val_acc: 0.7327\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8362 - acc: 0.7083 - val_loss: 0.8413 - val_acc: 0.7080\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8153 - acc: 0.7123 - val_loss: 0.7711 - val_acc: 0.7301\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8166 - acc: 0.7121 - val_loss: 0.7841 - val_acc: 0.7246\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7998 - acc: 0.7195 - val_loss: 0.7617 - val_acc: 0.7340\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7900 - acc: 0.7209 - val_loss: 0.7111 - val_acc: 0.7517\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7846 - acc: 0.7268 - val_loss: 0.7672 - val_acc: 0.7391\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7664 - acc: 0.7307 - val_loss: 0.7159 - val_acc: 0.7528\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7580 - acc: 0.7338 - val_loss: 0.6908 - val_acc: 0.7624\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7555 - acc: 0.7351 - val_loss: 0.6835 - val_acc: 0.7606\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7514 - acc: 0.7350 - val_loss: 0.7249 - val_acc: 0.7486\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7539 - acc: 0.7388 - val_loss: 0.6846 - val_acc: 0.7648\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7319 - acc: 0.7433 - val_loss: 0.6977 - val_acc: 0.7590\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7292 - acc: 0.7457 - val_loss: 0.6645 - val_acc: 0.7689\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7173 - acc: 0.7497 - val_loss: 0.7099 - val_acc: 0.7552\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7175 - acc: 0.7486 - val_loss: 0.6485 - val_acc: 0.7756\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7097 - acc: 0.7547 - val_loss: 0.6572 - val_acc: 0.7730\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6951 - acc: 0.7553 - val_loss: 0.6487 - val_acc: 0.7767\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6956 - acc: 0.7562 - val_loss: 0.7445 - val_acc: 0.7471\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6932 - acc: 0.7571 - val_loss: 0.6239 - val_acc: 0.7862\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6846 - acc: 0.7619 - val_loss: 0.6453 - val_acc: 0.7784\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6770 - acc: 0.7643 - val_loss: 0.6497 - val_acc: 0.7792\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6721 - acc: 0.7630 - val_loss: 0.6258 - val_acc: 0.7856\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6731 - acc: 0.7667 - val_loss: 0.6847 - val_acc: 0.7702\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6565 - acc: 0.7708 - val_loss: 0.6500 - val_acc: 0.7812\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6607 - acc: 0.7689 - val_loss: 0.6317 - val_acc: 0.7820\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6560 - acc: 0.7712 - val_loss: 0.6402 - val_acc: 0.7813\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6559 - acc: 0.7721 - val_loss: 0.6877 - val_acc: 0.7646\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6455 - acc: 0.7767 - val_loss: 0.7005 - val_acc: 0.7588\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6301 - acc: 0.7798 - val_loss: 0.6435 - val_acc: 0.7803\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6426 - acc: 0.7745 - val_loss: 0.6748 - val_acc: 0.7655\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6356 - acc: 0.7806 - val_loss: 0.6680 - val_acc: 0.7751\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6314 - acc: 0.7801 - val_loss: 0.5720 - val_acc: 0.8058\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6302 - acc: 0.7831 - val_loss: 0.6483 - val_acc: 0.7822\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6219 - acc: 0.7827 - val_loss: 0.6508 - val_acc: 0.7792\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.6191 - acc: 0.7858 - val_loss: 0.5799 - val_acc: 0.8026\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.6077 - acc: 0.7875 - val_loss: 0.6571 - val_acc: 0.7778\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.6125 - acc: 0.7861 - val_loss: 0.6178 - val_acc: 0.7889\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.6118 - acc: 0.7881 - val_loss: 0.6634 - val_acc: 0.7781\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.6032 - acc: 0.7895 - val_loss: 0.6401 - val_acc: 0.7834\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.6004 - acc: 0.7893 - val_loss: 0.5725 - val_acc: 0.8042\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5993 - acc: 0.7932 - val_loss: 0.6208 - val_acc: 0.7870\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5898 - acc: 0.7946 - val_loss: 0.5687 - val_acc: 0.8069\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5979 - acc: 0.7931 - val_loss: 0.5640 - val_acc: 0.8070\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5910 - acc: 0.7948 - val_loss: 0.6078 - val_acc: 0.7943\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6013 - acc: 0.7942 - val_loss: 0.6421 - val_acc: 0.7870\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5852 - acc: 0.7971 - val_loss: 0.5798 - val_acc: 0.8028\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5856 - acc: 0.7980 - val_loss: 0.7188 - val_acc: 0.7613\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5867 - acc: 0.7971 - val_loss: 0.6481 - val_acc: 0.7820\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5719 - acc: 0.8007 - val_loss: 0.5517 - val_acc: 0.8186\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5813 - acc: 0.7993 - val_loss: 0.6067 - val_acc: 0.7932\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5766 - acc: 0.7996 - val_loss: 0.6181 - val_acc: 0.7912\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5761 - acc: 0.8020 - val_loss: 0.6000 - val_acc: 0.7933\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5695 - acc: 0.8035 - val_loss: 0.5450 - val_acc: 0.8170\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5627 - acc: 0.8055 - val_loss: 0.5739 - val_acc: 0.8052\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5744 - acc: 0.8026 - val_loss: 0.6156 - val_acc: 0.7956\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5772 - acc: 0.8025 - val_loss: 0.5963 - val_acc: 0.8032\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5604 - acc: 0.8076 - val_loss: 0.5776 - val_acc: 0.8081\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5715 - acc: 0.8050 - val_loss: 0.5663 - val_acc: 0.8097\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5576 - acc: 0.8075 - val_loss: 0.5857 - val_acc: 0.8013\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5633 - acc: 0.8063 - val_loss: 0.5593 - val_acc: 0.8144\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5572 - acc: 0.8085 - val_loss: 0.5623 - val_acc: 0.8150\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5579 - acc: 0.8095 - val_loss: 0.5955 - val_acc: 0.7998\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5591 - acc: 0.8102 - val_loss: 0.5387 - val_acc: 0.8165\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5513 - acc: 0.8097 - val_loss: 0.6398 - val_acc: 0.7919\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5539 - acc: 0.8107 - val_loss: 0.5841 - val_acc: 0.8071\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5465 - acc: 0.8122 - val_loss: 0.5679 - val_acc: 0.8130\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5491 - acc: 0.8128 - val_loss: 0.6024 - val_acc: 0.8005\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5457 - acc: 0.8138 - val_loss: 0.5621 - val_acc: 0.8080\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5511 - acc: 0.8100 - val_loss: 0.5522 - val_acc: 0.8158\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5614 - acc: 0.8087 - val_loss: 0.5614 - val_acc: 0.8108\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5469 - acc: 0.8131 - val_loss: 0.5631 - val_acc: 0.8100\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5453 - acc: 0.8142 - val_loss: 0.5729 - val_acc: 0.8076\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5424 - acc: 0.8136 - val_loss: 0.5842 - val_acc: 0.8038\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5440 - acc: 0.8150 - val_loss: 0.5364 - val_acc: 0.8202\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5446 - acc: 0.8141 - val_loss: 0.5508 - val_acc: 0.8141\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5435 - acc: 0.8133 - val_loss: 0.5544 - val_acc: 0.8158\n",
            "___________________________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 1.9140 - acc: 0.2957 - val_loss: 1.6624 - val_acc: 0.3937\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.6646 - acc: 0.3897 - val_loss: 1.4864 - val_acc: 0.4657\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.5344 - acc: 0.4398 - val_loss: 1.3671 - val_acc: 0.5077\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.4512 - acc: 0.4715 - val_loss: 1.4199 - val_acc: 0.4994\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.3852 - acc: 0.4999 - val_loss: 1.3045 - val_acc: 0.5403\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.3161 - acc: 0.5264 - val_loss: 1.1680 - val_acc: 0.5805\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.2620 - acc: 0.5466 - val_loss: 1.1582 - val_acc: 0.5909\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.2230 - acc: 0.5619 - val_loss: 1.1181 - val_acc: 0.6005\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1830 - acc: 0.5755 - val_loss: 1.0957 - val_acc: 0.6141\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1563 - acc: 0.5867 - val_loss: 1.1264 - val_acc: 0.6038\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1177 - acc: 0.6000 - val_loss: 1.0504 - val_acc: 0.6386\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0887 - acc: 0.6117 - val_loss: 1.0168 - val_acc: 0.6448\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0609 - acc: 0.6218 - val_loss: 0.9698 - val_acc: 0.6612\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0436 - acc: 0.6292 - val_loss: 0.9036 - val_acc: 0.6856\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0168 - acc: 0.6404 - val_loss: 0.8744 - val_acc: 0.6965\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9850 - acc: 0.6486 - val_loss: 0.9483 - val_acc: 0.6733\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9739 - acc: 0.6548 - val_loss: 0.9585 - val_acc: 0.6772\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9496 - acc: 0.6621 - val_loss: 0.8075 - val_acc: 0.7238\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9339 - acc: 0.6700 - val_loss: 0.8651 - val_acc: 0.7004\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.9249 - acc: 0.6734 - val_loss: 0.8077 - val_acc: 0.7231\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8979 - acc: 0.6813 - val_loss: 0.7726 - val_acc: 0.7379\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8949 - acc: 0.6841 - val_loss: 0.7607 - val_acc: 0.7378\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8793 - acc: 0.6930 - val_loss: 0.8035 - val_acc: 0.7185\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8611 - acc: 0.6977 - val_loss: 0.7494 - val_acc: 0.7417\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8529 - acc: 0.6999 - val_loss: 0.7210 - val_acc: 0.7499\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8332 - acc: 0.7061 - val_loss: 0.7314 - val_acc: 0.7480\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8268 - acc: 0.7060 - val_loss: 0.7246 - val_acc: 0.7491\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8187 - acc: 0.7086 - val_loss: 0.7186 - val_acc: 0.7488\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8004 - acc: 0.7174 - val_loss: 0.6858 - val_acc: 0.7624\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7924 - acc: 0.7216 - val_loss: 0.8614 - val_acc: 0.7143\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7871 - acc: 0.7218 - val_loss: 0.7385 - val_acc: 0.7494\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7797 - acc: 0.7280 - val_loss: 0.7015 - val_acc: 0.7564\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7619 - acc: 0.7328 - val_loss: 0.6668 - val_acc: 0.7712\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7670 - acc: 0.7303 - val_loss: 0.6644 - val_acc: 0.7670\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7529 - acc: 0.7358 - val_loss: 0.6859 - val_acc: 0.7676\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7442 - acc: 0.7371 - val_loss: 0.6117 - val_acc: 0.7904\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7375 - acc: 0.7426 - val_loss: 0.6320 - val_acc: 0.7816\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7320 - acc: 0.7425 - val_loss: 0.6736 - val_acc: 0.7711\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7260 - acc: 0.7457 - val_loss: 0.6866 - val_acc: 0.7633\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7194 - acc: 0.7454 - val_loss: 0.6218 - val_acc: 0.7863\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7106 - acc: 0.7506 - val_loss: 0.6491 - val_acc: 0.7775\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.7084 - acc: 0.7508 - val_loss: 0.6279 - val_acc: 0.7885\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6913 - acc: 0.7584 - val_loss: 0.6138 - val_acc: 0.7868\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6994 - acc: 0.7575 - val_loss: 0.5793 - val_acc: 0.8008\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6902 - acc: 0.7603 - val_loss: 0.6087 - val_acc: 0.7903\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6796 - acc: 0.7629 - val_loss: 0.6075 - val_acc: 0.7911\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6781 - acc: 0.7614 - val_loss: 0.6395 - val_acc: 0.7783\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6691 - acc: 0.7666 - val_loss: 0.5965 - val_acc: 0.7976\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6714 - acc: 0.7650 - val_loss: 0.6051 - val_acc: 0.7916\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6594 - acc: 0.7694 - val_loss: 0.6204 - val_acc: 0.7900\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6483 - acc: 0.7724 - val_loss: 0.6635 - val_acc: 0.7747\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6522 - acc: 0.7736 - val_loss: 0.5733 - val_acc: 0.8062\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.6518 - acc: 0.7733 - val_loss: 0.5487 - val_acc: 0.8128\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6462 - acc: 0.7732 - val_loss: 0.5899 - val_acc: 0.7967\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6366 - acc: 0.7805 - val_loss: 0.6196 - val_acc: 0.7892\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6376 - acc: 0.7766 - val_loss: 0.6343 - val_acc: 0.7803\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6217 - acc: 0.7835 - val_loss: 0.5715 - val_acc: 0.8032\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6270 - acc: 0.7840 - val_loss: 0.5724 - val_acc: 0.8025\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6325 - acc: 0.7802 - val_loss: 0.6336 - val_acc: 0.7913\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.6119 - acc: 0.7869 - val_loss: 0.6003 - val_acc: 0.7954\n",
            "Epoch 61/100\n",
            " 858/1000 [========================>.....] - ETA: 3s - loss: 0.6103 - acc: 0.7862"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PjkW--T4jVDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Print(\"Overall validation accuracy:\", sum(scores)/5)\n",
        "\n",
        "score = model.evaluate(test_X, test_Y, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}